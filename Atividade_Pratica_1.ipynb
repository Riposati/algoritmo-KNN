{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ph9wRVbJhEW4"
   },
   "source": [
    "# Atividade 01: Implementando um Classificador *k Vizinhos Mais Próximos* (*kNN*)\n",
    "\n",
    "Nesta atividade, você irá treinar um classificador *kNN* e irá testá-lo utilizando o dataset CIFAR-10;\n",
    "\n",
    "O classificador *kNN* consiste de duas etapas:\n",
    "\n",
    "1. Durante o treinamento, o classificador simplesmente armazena os dados de treinamento\n",
    "2. Durante o teste, o classificador calcula a distância entre cada objeto de teste e todos os dados de treinamento, utilizando os rótulos dos k mais similares (ou próximos) para determinar o rótulo dos objetos de teste\n",
    "\n",
    "O valor de $k$ pode ser determinado via validação cruzada, por exemplo.\n",
    "\n",
    "Neste atividade, você irá:\n",
    "\n",
    "- testar a implementação dos passos de **treinamento e teste de um classificador kNN**\n",
    "- **entender as etapas** básicas (*pipeline*) **da classificação de imagens**\n",
    "- **explorar** o uso da **validação cruzada** \n",
    "- **explorar a escrita de código** eficiente e paralelo/vetorizado\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tNhHtwlhhEW-"
   },
   "source": [
    "## Preparação para usar o *Colaboratory*\n",
    "\n",
    "Caso você deseje usar o *Colaborabory*, execute os comandos da célula a seguir para conseguir acessar os arquivos em uma conta do **Google Drive**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "Y9vSpkguhEXC",
    "outputId": "fe1e15a5-0904-48be-c4e5-90b17b18cc05"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5HHH672NhEXQ"
   },
   "source": [
    "Além disso, você talvez deseje trabalhar um subdiretório (ou pasta) específico, por exemplo `Pratica1`.  Esse diretório (ou pasta) já deve ter sido criado e conter o ***notebook*** dessa prática.\n",
    "\n",
    "Sendo assim, utilize as instruções na próxima célula para alterar o diretório corrente para esse subdiretório (alterando o nome do subdiretório, se for o caso)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DeiIo8j6hEXT"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"drive/My Drive/Pratica1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KFNlhz3yhEXb"
   },
   "source": [
    "## Obtendo o conjunto de dados CIFAR-10\n",
    "\n",
    "Nesta atividade, você irá desenvolver uma rede neural para realizar classificação de imagens e irá testá-la utilizando o dataset CIFAR-10. \n",
    "\n",
    "Para tando, você deve obter as imagens dessa base de dados executando a célula a seguir.\n",
    "\n",
    "**OBS: Você só precisar realizar esta etapa uma vez!** Caso você já a tenha feito anteriormente e está retornando para continuar a execução dessa prática, não será necessário que se faça a recuperação das imagens novamente. Para verificar se os dados da base estão disponíveis, basta checar a existência do subdiretório `cifar-10-batches-py` no diretório corrente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "yhb7OmIZhEXf",
    "outputId": "e6eb43bc-a052-4e40-85ba-3b75960114d8"
   },
   "outputs": [],
   "source": [
    "!wget http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
    "!tar -xzvf cifar-10-python.tar.gz\n",
    "!rm cifar-10-python.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YAk2PbUzhEXn"
   },
   "source": [
    "## Código de inicialização e configuração básica\n",
    "\n",
    "Execute a célula a seguir para garantir a importação de alguns recursos básicos, bem como a inicialização/configuração para exibição correta de gráficos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "tkqNPWE7hEXq",
    "outputId": "eafe7a1d-d77c-48d9-89a4-52af5ffd2c5d"
   },
   "outputs": [],
   "source": [
    "# Executa algum código de inicialização desse notebook.\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from past.builtins import xrange\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "# Um pouco de 'mágica': Isto permite que as figuras geradas pela biblioteca matplotlib apareçam dentro do notebook\n",
    "# ao invés de aparecer em uma nova janela.\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # fixa tamanho default para as plotagens\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Um pouco mais de 'mágica', assim o notebook irá recarregar módulos python externos;\n",
    "# veja mais em http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Aa7JfOthEXx"
   },
   "source": [
    "# Carregamento de dados\n",
    "Agora que você testou uma rede de duas camadas passando pela verificação de gradientes e seu funcionado sobre o pequeno conjunto de dados, é hora de carregar os dados do **CIFAR-10 dataset** de modo que você possa usá-los no treinamento de um classificador sobre dados reais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "id": "wRvd1GaMhEXz",
    "outputId": "261b5341-79d7-4571-aeda-2f82b5570048"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from six.moves import cPickle as pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import platform\n",
    "\n",
    "def load_pickle(f):\n",
    "    version = platform.python_version_tuple()\n",
    "    if version[0] == '2':\n",
    "        return  pickle.load(f)\n",
    "    elif version[0] == '3':\n",
    "        return  pickle.load(f, encoding='latin1')\n",
    "    raise ValueError(\"invalid python version: {}\".format(version))\n",
    "\n",
    "def load_CIFAR_batch(filename):\n",
    "  \"\"\" load single batch of cifar \"\"\"\n",
    "  with open(filename, 'rb') as f:\n",
    "    datadict = load_pickle(f)\n",
    "    X = datadict['data']\n",
    "    Y = datadict['labels']\n",
    "    X = X.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"float\")\n",
    "    Y = np.array(Y)\n",
    "    return X, Y\n",
    "\n",
    "def load_CIFAR10(ROOT):\n",
    "  \"\"\" load all of cifar \"\"\"\n",
    "  xs = []\n",
    "  ys = []\n",
    "  for b in range(1,6):\n",
    "    f = os.path.join(ROOT, 'data_batch_%d' % (b, ))\n",
    "    X, Y = load_CIFAR_batch(f)\n",
    "    xs.append(X)\n",
    "    ys.append(Y)    \n",
    "  Xtr = np.concatenate(xs)\n",
    "  Ytr = np.concatenate(ys)\n",
    "  del X, Y\n",
    "  Xte, Yte = load_CIFAR_batch(os.path.join(ROOT, 'test_batch'))\n",
    "  return Xtr, Ytr, Xte, Yte\n",
    "\n",
    "# Carrega os dados brutos da base CIFAR-10.\n",
    "# Para tanto, você deve ter feito o download de http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
    "cifar10_dir = 'cifar-10-batches-py'\n",
    "X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "\n",
    "# Apenas para verificação, vamos exibir o tamanho dos dados de treinamento e teste.\n",
    "print('Training data shape: ', X_train.shape)\n",
    "print('Training labels shape: ', y_train.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ShvkeyHchEX6"
   },
   "source": [
    "## Visualizando amostras dos dados\n",
    "Utilize a célula a seguir para visualizar algumas amostras das 10 classes de imagens da base `CIFAR-10`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "id": "rvkLvLd_hEX8",
    "outputId": "cfd56095-bbe8-4606-b8db-933a6f38478c"
   },
   "outputs": [],
   "source": [
    "# Visualizar alguns exemplos do dataset.\n",
    "# São exibidos apenas 7 exemplos de imagens de treinamento de cada classe.\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "num_classes = len(classes)\n",
    "samples_per_class = 7\n",
    "for y, cls in enumerate(classes):\n",
    "    idxs = np.flatnonzero(y_train == y)\n",
    "    idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
    "    for i, idx in enumerate(idxs):\n",
    "        plt_idx = i * num_classes + y + 1\n",
    "        plt.subplot(samples_per_class, num_classes, plt_idx)\n",
    "        plt.imshow(X_train[idx].astype('uint8'))\n",
    "        plt.axis('off')\n",
    "        if i == 0:\n",
    "            plt.title(cls)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hc01OXezhEYG"
   },
   "source": [
    "## Preparação de dados\n",
    "É importante para facilitar o treinamento que seja feito algum tipo de preparação dos dados. Neste caso, está se realizando uma simples subamostragem dos dados para maior eficiência na execução do código dessa atividade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "id": "s7JP5n4UhEYG",
    "outputId": "9b779eb3-aaf3-432c-ec9d-12ab9c67a136"
   },
   "outputs": [],
   "source": [
    "# Realiza subamostragem dos dados para maior eficiência na execução do código desse exercício\n",
    "num_training = 5000\n",
    "mask = list(range(num_training))\n",
    "X_train = X_train[mask]\n",
    "y_train = y_train[mask]\n",
    "\n",
    "num_test = 500\n",
    "mask = list(range(num_test))\n",
    "X_test = X_test[mask]\n",
    "y_test = y_test[mask]\n",
    "\n",
    "# Reformata os dados das imagens, assim as matrizes são transformadas em vetores\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R48Z07qlhEYO"
   },
   "source": [
    "## Código para Classe implementando o Classificador *kNN*\n",
    "\n",
    "Nesta atividade será utilizada a classe `KNearestNeighbor`  para representar instâncias de um classificador *kNN*. Esta classe se encontra definida dentro da célula abaixo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VuNpg0MIhEYQ"
   },
   "outputs": [],
   "source": [
    "class KNearestNeighbor(object):\n",
    "  \"\"\" a kNN classifier with L2 distance \"\"\"\n",
    "\n",
    "  def __init__(self):\n",
    "    pass\n",
    "\n",
    "  def train(self, X, y):\n",
    "    \"\"\"\n",
    "    Train the classifier. For k-nearest neighbors this is just \n",
    "    memorizing the training data.\n",
    "\n",
    "    Inputs:\n",
    "    - X: A numpy array of shape (num_train, D) containing the training data\n",
    "      consisting of num_train samples each of dimension D.\n",
    "    - y: A numpy array of shape (N,) containing the training labels, where\n",
    "         y[i] is the label for X[i].\n",
    "    \"\"\"\n",
    "    self.X_train = X\n",
    "    self.y_train = y\n",
    "    \n",
    "  def predict(self, X, k=1, num_loops=0):\n",
    "    \"\"\"\n",
    "    Predict labels for test data using this classifier.\n",
    "\n",
    "    Inputs:\n",
    "    - X: A numpy array of shape (num_test, D) containing test data consisting\n",
    "         of num_test samples each of dimension D.\n",
    "    - k: The number of nearest neighbors that vote for the predicted labels.\n",
    "    - num_loops: Determines which implementation to use to compute distances\n",
    "      between training points and testing points.\n",
    "\n",
    "    Returns:\n",
    "    - y: A numpy array of shape (num_test,) containing predicted labels for the\n",
    "      test data, where y[i] is the predicted label for the test point X[i].  \n",
    "    \"\"\"\n",
    "    if num_loops == 0:\n",
    "      dists = self.compute_distances_no_loops(X)\n",
    "    elif num_loops == 1:\n",
    "      dists = self.compute_distances_one_loop(X)\n",
    "    elif num_loops == 2:\n",
    "      dists = self.compute_distances_two_loops(X)\n",
    "    else:\n",
    "      raise ValueError('Invalid value %d for num_loops' % num_loops)\n",
    "\n",
    "    return self.predict_labels(dists, k=k)\n",
    "\n",
    "  def compute_distances_two_loops(self, X):\n",
    "    \"\"\"\n",
    "    Compute the distance between each test point in X and each training point\n",
    "    in self.X_train using a nested loop over both the training data and the \n",
    "    test data.\n",
    "\n",
    "    Inputs:\n",
    "    - X: A numpy array of shape (num_test, D) containing test data.\n",
    "\n",
    "    Returns:\n",
    "    - dists: A numpy array of shape (num_test, num_train) where dists[i, j]\n",
    "      is the Euclidean distance between the ith test point and the jth training\n",
    "      point.\n",
    "    \"\"\"\n",
    "    num_test = X.shape[0]\n",
    "    num_train = self.X_train.shape[0]\n",
    "    dists = np.zeros((num_test, num_train))\n",
    "    for i in xrange(num_test):\n",
    "      for j in xrange(num_train):\n",
    "        dists[i, j] = np.sqrt(np.sum(np.square(self.X_train[j] - X[i])))\n",
    "    return dists\n",
    "\n",
    "  def compute_distances_one_loop(self, X):\n",
    "    \"\"\"\n",
    "    Compute the distance between each test point in X and each training point\n",
    "    in self.X_train using a single loop over the test data.\n",
    "\n",
    "    Input / Output: Same as compute_distances_two_loops\n",
    "    \"\"\"\n",
    "    num_test = X.shape[0]\n",
    "    num_train = self.X_train.shape[0]\n",
    "    dists = np.zeros((num_test, num_train))\n",
    "    for i in xrange(num_test):\n",
    "      dists[i, :] = np.sqrt(np.sum(np.square(self.X_train - X[i,:]), axis = 1))\n",
    "    return dists\n",
    "\n",
    "  def compute_distances_no_loops(self, X):\n",
    "    \"\"\"\n",
    "    Compute the distance between each test point in X and each training point\n",
    "    in self.X_train using no explicit loops.\n",
    "\n",
    "    Input / Output: Same as compute_distances_two_loops\n",
    "    \"\"\"\n",
    "    num_test = X.shape[0]\n",
    "    num_train = self.X_train.shape[0]\n",
    "    dists = np.zeros((num_test, num_train)) \n",
    "    x2 = np.sum(X**2, axis=1).reshape((num_test,1))\n",
    "    y2 = np.sum(self.X_train**2, axis=1).reshape((1,num_train))\n",
    "    xy = X.dot(self.X_train.T)\n",
    "    dists = np.sqrt(x2+y2-2*xy)\n",
    "    return dists\n",
    "\n",
    "  def predict_labels(self, dists, k=1):\n",
    "    \"\"\"\n",
    "    Given a matrix of distances between test points and training points,\n",
    "    predict a label for each test point.\n",
    "\n",
    "    Inputs:\n",
    "    - dists: A numpy array of shape (num_test, num_train) where dists[i, j]\n",
    "      gives the distance betwen the ith test point and the jth training point.\n",
    "\n",
    "    Returns:\n",
    "    - y: A numpy array of shape (num_test,) containing predicted labels for the\n",
    "      test data, where y[i] is the predicted label for the test point X[i].  \n",
    "    \"\"\"\n",
    "    num_test = dists.shape[0]\n",
    "    y_pred = np.zeros(num_test)\n",
    "    for i in xrange(num_test):\n",
    "      # A list of length k storing the labels of the k nearest neighbors to\n",
    "      # the ith test point.\n",
    "      closest_y = []\n",
    "      closest_y = self.y_train[np.argsort(dists[i,:])[:k]]\n",
    "      y_pred[i] = np.argmax(np.bincount(closest_y))\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "# Cria uma instância do classificador kNN. \n",
    "# Lembre-se que o treinamento de um classificador kNN é trivial: \n",
    "# o classificador simplemente armazena os dados sem nenhum processamento adicional \n",
    "classifier = KNearestNeighbor()\n",
    "classifier.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yUjW3P2YhEYX"
   },
   "source": [
    "Agora, você deve classificar os dados de teste com o classificador kNN. Lembre-se de que esse processo pode ser dividido em dois passos:\n",
    "\n",
    "1. Primeiro, deve-se calcular as distâncias entre todas as amostras de teste e todos os dados de treinamento.\n",
    "2. Dadas essas distâncias, para cada amostra de teste, deve-se encontrar os k exemplos mais próximos entre os dados de treinamento e utilizá-los para uma **votação**, de forma a determinar o rótulo da amostra teste.\n",
    "\n",
    "Vamos iniciar calculando a matriz de distância entre todos os dados de treinamento e amostras de teste. Por exemplo, se existirem **Ntr** exemplos de treinamento e **Nte** amostras de teste, esta etapa resulta em uma matriz **Nte x Ntr**, em que cada elemento (*i*, *j*) representa a distância entre a *i*-ésima amostra de teste e o *j*-ésimo exemplos de treinamento. \n",
    "\n",
    "Primeiramente, você deve experimentar com a função `compute_distances_two_loops` que utiliza dois laços (muito ineficiente) para iterar sobre todos os pares de exemplos (teste, treino) e calcular a matriz de distância (um elemento por vez)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "VyM1S3r_hEYZ",
    "outputId": "2e465a7c-6d59-49b7-c4c7-940b8c205af3"
   },
   "outputs": [],
   "source": [
    "dists = classifier.compute_distances_two_loops(X_test)\n",
    "print(dists.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IPn3zoi7hEYg"
   },
   "source": [
    "## Visualizando a Matriz de Distâncias do Classificador *kNN*\n",
    "\n",
    "O código da célula abaixo pode ser usado para se visualizar a matriz de distância: cada linha está associada a uma única amostra de teste e suas distâncias para os exemplos de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "id": "F-RrZsEzhEYj",
    "outputId": "be832790-649d-4e34-8979-0abc944a8da2"
   },
   "outputs": [],
   "source": [
    "# Pode-se visualizar a matriz de distância: cada linha está associada a uma única amostra de teste\n",
    "# e suas distâncias para os exemplos de treinamento\n",
    "plt.imshow(dists, interpolation='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zfwzV5NehEYo"
   },
   "source": [
    "**Pergunta #1:** Observe os padrões que surgem na matriz de distância, em que algumas linhas e colunas são visivelmente mais claras (vale dizer que o esquema de cores padrão que foi utilizado, preto indica distâncias pequenas enquanto branco representa distâncias grandes).\n",
    "\n",
    "- O que você pode dizer sobre os dados que explique as linhas mais claras?\n",
    "- E, em relação as colunas mais claras?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eb4JylaShEYr"
   },
   "source": [
    "**Sua Resposta**: *Preencha aqui.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F4uTCkxchEYs"
   },
   "source": [
    "## Realizando Predições com o Classificador *kNN*\n",
    "\n",
    "Em seguida, pode-se realizar predições utilizando a matriz de distância calculada. Para tanto, você utilizar a função `predict_labels`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "PMMKmfAphEYv",
    "outputId": "0401da02-eaeb-4b4c-ca12-5c76a8bcd89a"
   },
   "outputs": [],
   "source": [
    "# Agora, você pode testar a função predict_labels executando o código a seguir:\n",
    "# Utilizou-se k = 1 (que representa o suo apenas do VIZINHO MAIS PRÓXIMO).\n",
    "y_test_pred = classifier.predict_labels(dists, k=1)\n",
    "\n",
    "# Calcula e exibe a fração de amostras corretamente preditas\n",
    "num_correct = np.sum(y_test_pred == y_test)\n",
    "accuracy = float(num_correct) / num_test\n",
    "print('Got %d / %d correct => accuracy: %f' % (num_correct, num_test, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mF3k6-PehEY1"
   },
   "source": [
    "Você deve esperar ver aproximadamente `27%` de acurácia. Agora, vamos experimentar com um valor maior de `k`, p.ex. `k = 5`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "hjUPpbCChEY3",
    "outputId": "df80b1e4-a5e9-4cab-d4e6-4f9d9cd3d16f"
   },
   "outputs": [],
   "source": [
    "y_test_pred = classifier.predict_labels(dists, k=5)\n",
    "num_correct = np.sum(y_test_pred == y_test)\n",
    "accuracy = float(num_correct) / num_test\n",
    "print('Got %d / %d correct => accuracy: %f' % (num_correct, num_test, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "elruABWlhEY-"
   },
   "source": [
    "Você deve esperar ver uma performance ligeiramente melhor que a obtida com `k = 1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EF-wHT2ahEY_"
   },
   "source": [
    "## Explorando o paralelismo para melhorar a eficiência\n",
    "\n",
    "Agora, vamos tentar aumentar a velocidade de execução utilizando operações vetoriais!\n",
    "\n",
    "Primeiro, elimina-se uma dos laços...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "HnhPjRI9hEZC",
    "outputId": "984860f1-4df5-490d-a3e3-6af346bc5fdb"
   },
   "outputs": [],
   "source": [
    "# Primeiro, vamos acelerar o cálculo da matriz de distância por meio da paralelização \n",
    "# de um dos laços. A implementação se encontra na função compute_distances_one_loop \n",
    "# dentro da classe KNearestNeighbor\n",
    "\n",
    "# Examine o código da função e, depois, execute o código abaixo:\n",
    "dists_one = classifier.compute_distances_one_loop(X_test)\n",
    "\n",
    "# Para se garantir que sua implementação paralelizada está correta, deve-se verificar\n",
    "# que seu resultado coincide com o da implementação ingênua (ou trivial).\n",
    "\n",
    "# Existem várias de se decidir se duas matrizes são similares; uma das formas mais \n",
    "# simples é a norma de Frobenius. Caso você não a conheça, a norma de Frobenius de \n",
    "# duas matrizes é a raiz quadrada da soma dos quadrados das diferenças entre todos  \n",
    "# os elementos correspondentes das duas matrizes. Em outras palavras, é como se \n",
    "# reformatássemos as matrizes como vetores e calculássemos a distância euclidiana\n",
    "# entre eles.\n",
    "\n",
    "difference = np.linalg.norm(dists - dists_one, ord='fro')\n",
    "print('Difference was: %f' % (difference, ))\n",
    "if difference < 0.001:\n",
    "    print('Good! The distance matrices are the same')\n",
    "else:\n",
    "    print('Uh-oh! The distance matrices are different')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-S55n1XhEZR"
   },
   "source": [
    "Em seguida, vamos **eliminar todos os laços!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "UMjMcRpyhEZT",
    "outputId": "1454df1a-72e2-402b-c238-9a8a747590c7"
   },
   "outputs": [],
   "source": [
    "# Em seguida, utiliza o cálculo da matriz de distância completamente vetorizado \n",
    "#por meio da função compute_distances_no_loops e teste com o código abaixo\n",
    "dists_two = classifier.compute_distances_no_loops(X_test)\n",
    "\n",
    "# Verifique se a matriz de distância obtida coincide com a calculada anteriormente:\n",
    "difference = np.linalg.norm(dists - dists_two, ord='fro')\n",
    "print('Difference was: %f' % (difference, ))\n",
    "if difference < 0.001:\n",
    "    print('Good! The distance matrices are the same')\n",
    "else:\n",
    "    print('Uh-oh! The distance matrices are different')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bbMR0lpQhEZZ"
   },
   "source": [
    "Vamos comparar a eficiência dessas três implementações!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "p2VPbt_mhEZa",
    "outputId": "4616b835-4cf3-4181-84db-366265e61f05"
   },
   "outputs": [],
   "source": [
    "# Agora, pode-se comparar a velocidade de suas implementações\n",
    "def time_function(f, *args):\n",
    "    \"\"\"\n",
    "    Chama uma funcao f com args e retorna o tempo (em segundos) que ela levou para executar.\n",
    "    \"\"\"\n",
    "    import time\n",
    "    tic = time.time()\n",
    "    f(*args)\n",
    "    toc = time.time()\n",
    "    return toc - tic\n",
    "\n",
    "two_loop_time = time_function(classifier.compute_distances_two_loops, X_test)\n",
    "print('Two loop version took %f seconds' % two_loop_time)\n",
    "\n",
    "one_loop_time = time_function(classifier.compute_distances_one_loop, X_test)\n",
    "print('One loop version took %f seconds' % one_loop_time)\n",
    "\n",
    "no_loop_time = time_function(classifier.compute_distances_no_loops, X_test)\n",
    "print('No loop version took %f seconds' % no_loop_time)\n",
    "\n",
    "# OBS: você deve ver uma execução significativamente mais rápida com a implementação completamente vetorizada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FdncPSB2hEZg"
   },
   "source": [
    "### Validação cruzada\n",
    "\n",
    "Nesse ponto, você já implementou o classificador kNN, contudo o valor de k = 5 foi definido de forma arbitrária.\n",
    "\n",
    "Pode-se agora procurar determinar o melhor valor para esse hiperparâmetro por meio de validação cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "5qoY8iPZhEZh",
    "outputId": "79865eab-2717-4cb4-c8b1-d7553e28e895"
   },
   "outputs": [],
   "source": [
    "num_folds = 5\n",
    "k_choices = [1, 3, 5, 8, 10, 12, 15, 20, 50, 100]\n",
    "\n",
    "X_train_folds = []\n",
    "y_train_folds = []\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Dividir os dados de treinamento em partições. Depois disso, X_train_folds    #\n",
    "# e y_train_folds devem ser listas de tamanho num_folds, em que:               #\n",
    "# y_train_folds[i] é o vetor de rótulos para os pontos em X_train_folds[i].    #\n",
    "# DICA: Experimente usar a função array_split da biblioteca numpy.             #\n",
    "################################################################################\n",
    "pass\n",
    "X_train_folds = np.array_split(X_train, num_folds)\n",
    "y_train_folds = np.array_split(y_train, num_folds)\n",
    "\n",
    "#print(X_train_folds)\n",
    "#print(y_train_folds)\n",
    "\n",
    "################################################################################\n",
    "#                              FIM DE SEU CÓDIGO                               #\n",
    "################################################################################\n",
    "\n",
    "# Declarou-se a seguir um dicionário para conter os valores de acurácia para \n",
    "# diferentes valores de k que forem encontrados durante a validação cruzada.\n",
    "#\n",
    "\n",
    "k_to_accuracies = {}\n",
    "\n",
    "# Depois de executada a validação cruzada, espera-se que k_to_accuracies[k] \n",
    "# seja uma lista de tamanho igual a num_folds contendo os diferentes valores \n",
    "# de acurácia associados a esse valor de k que foram obtidos para cada um dos\n",
    "# particionamentos\n",
    "\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Realizar a validação cruzada de k subconjuntos (folds) para encontrar o      #\n",
    "# melhor valor de k. Para cada valor possível de k, executar o classificador   #\n",
    "# kNN várias vezes (num_folds repetições), de forma que em cada execução       #\n",
    "# todos com exceção de um dos subconjuntos (folds) são usados como dados de    #\n",
    "# treinamento e o subconjunto deixado a parte é usado como conjunto de         #\n",
    "# validação. Armazenar as acurácias obtidas para todos os subconjuntos e para  #\n",
    "# todos os valores de k no dicionário denominado k_to_accuracies.              # \n",
    "################################################################################\n",
    "pass\n",
    "\n",
    "aux = num_folds-1 # 4 no caso \n",
    "classifier = KNearestNeighbor() # novo objeto KNN\n",
    "accuracy = 0.0\n",
    "\n",
    "for k in k_choices: # executa 10 vezes no caso\n",
    "\n",
    "  for fold in range(num_folds): # executa 5 vezes no caso\n",
    "\n",
    "    if fold!=aux: # uso todos os outros diferentes do fold atual para treinar o algoritmo\n",
    "\n",
    "      classifier.train(X_train_folds[fold], y_train_folds[fold]) # treino com todos menos o fold atual\n",
    "\n",
    "    if fold==aux: # valido o fold  \n",
    "    \n",
    "      y_test_pred = classifier.predict(X_train_folds[aux], k) # uso para testar os outros\n",
    "      \n",
    "      #print((y_test_pred))\n",
    "      #print(\"aux => {}\".format(aux))\n",
    "      #print(\"fold => {}\".format(fold))\n",
    "\n",
    "      # Calcula e exibe a acurácia\n",
    "      num_correct = np.sum(y_test_pred == y_train_folds[aux]) # detalhe importante para não dar errado pois y_test não é o fold que quero atual\n",
    "      #print(num_correct)\n",
    "      accuracy = float(num_correct) / num_test\n",
    "      #print('Got %d / %d correct => accuracy: %f' % (num_correct, num_test, accuracy))\n",
    "\n",
    "    k_to_accuracies[k] = [accuracy]\n",
    "\n",
    "  aux -= 1 # esta parte esta correta para variar o aux e o fold igual no conteudo teorico\n",
    "\n",
    "  if aux < 0:\n",
    "    aux = num_folds-1\n",
    "\n",
    "################################################################################\n",
    "#                              FIM DE SEU CÓDIGO                               #\n",
    "################################################################################\n",
    "\n",
    "# Exibe as acurácias calculadas\n",
    "for k in sorted(k_to_accuracies):\n",
    "    for accuracy in k_to_accuracies[k]:\n",
    "        print('k = %d, accuracy = %f' % (k, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gxhCP4wZhEZm"
   },
   "source": [
    "## Representando graficamente os resultados obtidos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "id": "uEJAj6RhhEZp",
    "outputId": "6ff6ac35-da22-4b63-8f56-e9906f6cbd71"
   },
   "outputs": [],
   "source": [
    "# Plota as observações brutas\n",
    "for k in k_choices:\n",
    "    accuracies = k_to_accuracies[k]\n",
    "    plt.scatter([k] * len(accuracies), accuracies)\n",
    "\n",
    "# Plota linha de tendência com barras de erro que correspondem ao desvio padrão \n",
    "accuracies_mean = np.array([np.mean(v) for k,v in sorted(k_to_accuracies.items())])\n",
    "accuracies_std = np.array([np.std(v) for k,v in sorted(k_to_accuracies.items())])\n",
    "plt.errorbar(k_choices, accuracies_mean, yerr=accuracies_std)\n",
    "plt.title('Cross-validation on k')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Cross-validation accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E2LRWEbGhEZu"
   },
   "source": [
    "## Selecionando um valor ideal para *k* e realizando o teste\n",
    "\n",
    "Com base nos resultados anterioes da validação cruzada, escolha o melhor valor para *k* (e insira na primeiro linha da célula abaixo como 'best_k'). Em seguida, treine novamente o classificador e realize os testes.\n",
    "\n",
    "Você deve ser capaz de obter uma acurácia acima de 28% nos dados de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "2VaXWDuKhEZv",
    "outputId": "93f8c8ab-0e2d-473f-ff84-b8449ce4c26b"
   },
   "outputs": [],
   "source": [
    "best_k = max(k_to_accuracies, key=k_to_accuracies.get)\n",
    "\n",
    "classifier = KNearestNeighbor()\n",
    "classifier.train(X_train, y_train)\n",
    "y_test_pred = classifier.predict(X_test, k=best_k)\n",
    "print((\"melhor qtd de vizinhos => {}\").format(best_k))\n",
    "\n",
    "# Calcula e exibe a acurácia\n",
    "num_correct = np.sum(y_test_pred == y_test)\n",
    "accuracy = float(num_correct) / num_test\n",
    "print('Got %d / %d correct => accuracy: %f' % (num_correct, num_test, accuracy))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Atividade-Pratica-1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
